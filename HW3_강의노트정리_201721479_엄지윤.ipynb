{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강의노트 정리 - 텍스트 마이닝의 이론과 실제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    " > 1. 텍스트 마이닝의 이해 \n",
    "  > 2. 텍스트 마이닝 방법론\n",
    "     - 도구 및 원리의 이해\n",
    "   > 3. 텍스트 마이닝의 문제점\n",
    "    >4. 문제 해결을 위한 방안\n",
    "     - 기존의 방법\n",
    "     - 딥러닝에 의한 방법\n",
    " >\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텍스트 마이닝의 이해\n",
    "### 1-1 텍스트 마이닝이란?\n",
    "\n",
    " - 비정형 데이터인 텍스트로부터 정형 데이터화.\n",
    " - 텍스트 마이닝을 위해서는 자연어처리를 통해 Vector화 해야함.\n",
    " \n",
    "### 1-2 텍스트 마이닝 방법\n",
    " > NLP\n",
    "  - Tokenize, stemming, lemmatize\n",
    "  - Chunking\n",
    "  - BOW, TFIDF\n",
    "  \n",
    " > 머신러닝\n",
    "  - Naïve Bayes, Logistic egression, Decision tree, SVM\n",
    "  - Embedding(Word2Vec, Doc2Vec)\n",
    "  - RNN(LSTM), Attention, Transformer\n",
    "  \n",
    "### 1-3 텍스트 마이닝의 단계\n",
    " > Doc.->tokenize,normalize -> Sequence of normalized words\n",
    "  > Sequence of normalized words \n",
    "   - 1) Fixed size vector without sequence info.ex) BOW, TFIDF\n",
    "   - 2) Fixed size vector with sequence info.ex) Doc2Vec\n",
    "   - 3) Series of Word Embedding with sequence info.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텍스트 마이닝의 기본도구 \n",
    " - 목적 : doc,sentence 등을 sparse vector로 변환\n",
    "### 2-1 Tokenize\n",
    " - Document를 Sentence의 집합으로 분리, Sentence를 Word의 집합으로 분리, 의미 없는 문자 등을 걸러 냄\n",
    "### 2-2 Text Normalization\n",
    " - 동일한 의미의 단어가 다른 형태를 갖는 것을 보완 e.g.) go <- goes,went\n",
    " - (1) Stemming (어간 추출) :의미가 아닌 규칙에 의한 변환,Porter Stemmer\n",
    " \n",
    " - (2) Lemmatization (표제어 추출) :사전을 이용하여 단어의 원형을 추출,     품사(part-of-speech)를 고려,WordNetLemmatizer\n",
    "### 2-3 POS-tagging\n",
    " - 최소단위에 대해 품사를 결정하여 할당, 품사태깅으로 해석하는 것이 정확함. \n",
    "### 2-4 Chunking\n",
    " - POS-tagging의 결과를 명사구, 형용사구, 분사구 등과 같은 말모듬으로 다시 합치는 과정\n",
    "### 2-5 BOW, TFIDF\n",
    " - tokenized 결과를 이용하여 문서를 vector로 표현\n",
    " \n",
    " > BOW \n",
    "  - Vector Space Model : 단어의 유/무 파악 , count vector : 유/무 아닌 단어 횟수파악\n",
    "  \n",
    "  - 활용 :Similarity Matching, Classify (감성분석)\n",
    "  \n",
    " >  TFIDF \n",
    "  - 단어의 count를 단어가 나타난 문서의 수로 나눠서 자주 등장하지 않는 단어의 weight를 올림.log(n/(1+df(t)) \n",
    "  \n",
    "  - 유사도 계산 : \n",
    "   - 1)TFIDF vector의 내적을 이용,\n",
    "   - 2)Cosine Similarity : 두 벡터의 길이가 다를 수 있으나 방향성(각도)만 고려하는 => 사용된 단어의 비율이 비슷하면 비슷한 문서로 간주\n",
    "\n",
    "### Text Classification with BOW/TFIDF\n",
    "\n",
    "#### (1) Naïve Bayes\n",
    " - 확률 P를 구하고 더 큰 쪽으로 결정\n",
    " \n",
    "#### (2) Logistic regression\n",
    " -  Ridge regression\n",
    " -  Lasso regression\n",
    " \n",
    "#### (3) Decision tree\n",
    " - Random Forest\n",
    " \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 텍스트 마이닝의 문제점\n",
    "\n",
    "### Curse of Dimensionality 차원의 저주 \n",
    "\n",
    " - 각 데이터 간의 거리가 너무 멀다 -> Dimension reduction 차원 축소\n",
    " - 차원축소 \n",
    " - 4장에서 자세히 다룸.\n",
    "  \n",
    "   \n",
    "### 단어 빈도의 불균형\n",
    "\n",
    " - 소수의 데이터가 결정적인 영향을 줌.\n",
    " - 너무 빈도가 높은 데이터는 유의미한 결과를 가져오지 못한다는 가정하에 빈도가 높은 단어를 삭제한다. \n",
    "\n",
    "### 단어가 쓰인 순서정보의 손실\n",
    "\n",
    " - 어떤 단어가 쓰였는지 안쓰였는지만 판단하다보니 문맥 context가 파악되지 않음. 이를 해결하기 위해 n-gram, deep learning 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.문제 해결을 위한 방안\n",
    "\n",
    "### 차원 축소\n",
    "\n",
    "   - (1) feature selection - 간단함.\n",
    "   - (2) feature extraction : PCA  방식 /LSA \n",
    "   - (3) Embedding : Word embedding, Document embedding\n",
    "   - (4) Deep Learning :RBM, Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
